featurePlot(x = training[,c("age", "education", "jobclass")],
y = training$wage,
plot = "pairs")
```
Visualizing data can be accomplished with qplot. We are looking for patterns, such as the positive trend between age and wages below, and separation of the data into two chunks below.
```{r}
require(ggplot2)
qplot(x = age, y = wage, data = training)
```
We should try to account for irregularities in the data **before** we build our model. The seperation of the data into two distinct groups is one exaple of of an irregularity that needs to be accounted for. If we colour the plot by different variables, we can sometimes understand these patterns better. The upper cluster in the above graph all represent jobs that belong to the information class, which may explain a lot of the difference between these classes of observation. For example, we can theorize that there within this age group, there there are some jobs which offer a disproportionatly higher wage, and that most of these jobs are information based.
```{r}
require(ggplot2)
qplot(x = age, y = wage, data = training, col=jobclass)
```
You should explore every avenue for explaining the patterns of the data. Below is the same plot coloured by education. Adding regression smoothers will fit a linear model to every different education class. This allows us to determine if there is a different relationship for different age groups.Here we see that for all educational levels, there is a slight positive relationship between seniority and wage
```{r}
qq<-qplot(x = age, y = wage, color =education, data = training)
qq + geom_smooth(method = "lm", formula = y~x)
```
If it apprears that different categories of data have differnt relationships, the data can be broken apart and examined seperately. Breaking numerical into categorical variables allows us to examine the data in different ways with different kinds of plots or tables.
```{r}
require(Hmisc)
cutWage<-cut2(training$wage, g=3)
table(cutWage)
p1<-qplot(x = cutWage,
y = age,
data = training,
fill=cutWage,
geom=c("boxplot")); p1
```
You can actually add the points themselves over the boxplots. This reveals the number of points, which are usually hidden by the boxplot
```{r}
p2<-qplot(cutWage, age,
data = training,
fill=cutWage,
geom=c("boxplot", "jitter")); p2
grid.arrange(p1, p2, ncol=2)
```
```{r}
# create table
t1<-table(cutWage, training$jobclass); t1
# proportions in each row
prop.table(t1,1)
```
Density plots for continuous values of predictors
```{r}
qplot(x = wage, color = education, data = training, geom = "density")
```
### Quiz 2 #2
Load the cement data using the commands:
```{r}
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
```
Make a plot of the outcome (CompressiveStrength) versus the index of the samples. Color by each of the variables in the data set (you may find the ```cut2()``` function in the Hmisc package useful for turning continuous covariates into factors). What do you notice in these plots?
```
1. The outcome variable is highly correlated with FlyAsh.
2. The data show a step like pattern that is perfectly explained by the FlyAsh variable so there may be a variable missing.
3. There is a step-like pattern in the plot of outcome versus index in the training set that isn't explained by any of the predictor variables so there may be a variable missing.
4. The data show a step like pattern that is perfectly explained by the Age variable.
```
```{r, message=FALSE}
require(Hmisc)
inds<-1:nrow(training)
# view step pattern in plot
q<-qplot(x = inds, y = CompressiveStrength, data = training); q
# apply a cut to all the columns of the training data
nameslist<-names(training)
cutall<-sapply(nameslist, function(nameslist){
cut2(training[[nameslist]], g=5)
})
cutall<-as.data.frame(cutall)
cutnames<-sapply(nameslist, function(nameslist){paste("cut", nameslist, sep="")})
colnames(cutall)<-cutnames
# plot the data coloured by the cuts in each of the variables
for(Var in names(cutall)) {
print(qplot(x = inds, y = CompressiveStrength, data=training, color=cutall[[Var]], main = Var))
}
```
If the data were strongly correlated with FlyAsh, we would expect the concentrations of FlyAsh to increase with the CompressiveStrength, but this is not the case, nor is it so for Age or any other variable. We conclude that a variable is missing.
###PreProcessing
Sometimes, the predictors which you have plotted can look very strange (or be distributed strangley), and need to be transformed before they can be used in prediction algorithms.
Why preprocess?
```{r}
library(kernlab); data(spam)
# partition the data into a training and test set
inTrain<-createDataPartition(y = spam$type,
p = 0.75,
list = F)
# subset the data into the training data
training<-spam[inTrain, ]
# the remainder goes into testing
testing<-spam[-inTrain, ]
hist(training$capitalAve, main ="", xlab="capital ave run length")
```
This is an example of a variable that is very skewed, and is hard to deal with in model based predictors, and should be preprocessed
```{r}
mean(training$capitalAve)
sd(training$capitalAve)
```
The standard deviation is *huge*. We need to preprocess so that the machine learning algorithms don't get tricked by the fact that this variable is skewed and highly variable.
One way that this could be done is with **Standarizing**
$$\frac{x-\bar{x}}{s_x}$$
```{r}
trainCapAve<-training$capitalAve
trainCapAveS<-(trainCapAve-mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAve)
sd(trainCapAve)
```
The **preProcess()** function can handle a lot of the standardization for you
```{r}
preObj<-preProcess(training[,-58], method=c("center", "scale"))
preObj
trainCapAve<-predict(preObj, training[,-58])$capitalAve
mean(trainCapAve)
sd(trainCapAve)
```
The preProcess command can be accepted by the train() function as an argument
```{r, warning=FALSE}
set.seed(32323)
modelFit<-train(type ~., data =training, preProcess=c("center", "scale"), method ="glm")
modelFit
```
library(caret)
preObj<-preProcess(training[,-58], method=c("center", "scale"))
preObj
trainCapAve<-predict(preObj, training[,-58])$capitalAve
c(mean(trainCapAve), sd(trainCapAve))
```
The preprocessing object that was created can be used to preprocess the test set.
```{r}
# preObj is the object we created by preprocessing the training set. If we pass the testing set to the predict function, the predict function will take the values calculated in the preprocessing step and apply them to the test set object
testCapAveS<-predict(preObj, testing[,-58])$capitalAve
c(mean(testCapAveS), sd(testCapAveS))
preObj<-preProcess(x = training[,-58], method = "BoxCox")
preObj
trainCapAveS<-predict(preObj, trainin[,-58])$capitalAve
trainCapAveS<-predict(preObj, training[,-58])$capitalAve
training$capAve<-training$capitalAve
selectNA<-rbinom(n = dim(training)[1], size = 1, prob = 0.05)==1
selectNA
sum(selectNA)
training$capAve<-training$capitalAve
selectNA<-rbinom(n = dim(training)[1], size = 1, prob = 0.05)==1
training$capAve[selectNA]<-NA
# Impute missing values and standardize
preObj<-preProcess(x = training[,-58], method = "knnImpute")
# predict on the training set all the new values, including those that have been imputed
capAve<-predict(preObj, training[,-58])$capAve
# standardize values
capAveTruth<-training$capitalAve
capAveTruth<-(capAveTruth-mean(capAveTruth))/sd(capAveTruth)
preObj<-preProcess(x = training[,-58], method = "knnImpute")
capAve<-predict(preObj, training[,-58])$capAve
predict(preObj, training[,-58])
capAve<-predict(preObj, training[,-58])$capAve
capAve<-predict(preObj, trainin[,-58])$capAve
capAve<-predict(preObj, training[,-58])$capAve
library(caret)
capAve<-predict(preObj, training[,-58])$capAve
capAve<-predict(preObj, training[,-58])$capAve
install.packages("RANN")
capAve<-predict(preObj, training[,-58])$capAve
table(training$jobclass)
data(Wage)
inTrain<-createDataPartition(y = Wage$wage,
p = 0.7,
list = F)
training<-Wage[inTrain, ]
testing<-Wage[-inTrain,]
table(training$jobclass)
dummies<-dummyVars(formula = wage~jobclass, data = training)
head(predict(object = dummies, newdata = training))
nearZeroVar(x = training, saveMetrics = T)
require(splines)
bsBasis<-bs(x = training$age, df = 3); bsBasis
head(bsBasis, 2)
head(bsBasis)
lm1<-lm(formula = wage~bsBasis,data = training)
plot(x = training$age, y = training$wage, pch=19, cex=0.5)
points(x = training$age, predict(object = lm1, newdata = training), color="red", pch=19)
points(x = training$age, predict(object = lm1, newdata = training), col="red", pch=19)
points(x = training$age, predict(object = lm1, newdata = training), col="red", pch=19, ces = 0.5)
points(x = training$age, predict(object = lm1, newdata = training), col="red", pch=19, cex = 0.5)
points(x = training$age, predict(object = lm1, newdata = training), col="red", pch=19, cex = 0.5)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
log(0)
inTrain<-createDataPartition(y = spam$type,
p = 0.75,
list = F)
# subset the data into the training data
training<-spam[inTrain, ]
# the remainder goes into testing
testing<-spam[-inTrain, ]
M<-abs(cor(training[,-58]))
M
diag(M)<-0
which(x = M>0.8, arr.ind = T)
data(spam)
# partition the data into a training and test set
inTrain<-createDataPartition(y = spam$type,
p = 0.75,
list = F)
# subset the data into the training data
training<-spam[inTrain, ]
# the remainder goes into testing
testing<-spam[-inTrain, ]
#calculate the correlation between all colums (except the last one, which is what we want to predict)
M<-abs(cor(training[,-58]))
# every variable has a corelation 1 with itself, so we set these to 0 before we identify which have high correlations
diag(M)<-0
# identify the variables that have a high correlation with each other
which(x = M > 0.8, arr.ind = T)
names(spam)
names(spam)[c(32,34,40)]
par(mfrow=c(1,3))
plot(spam[,32], spam[,34])
plot(spam[,32], spam[,40])
plot(spam[,34], spam[,40])
smallspam<-spam[, c(32, 34, 40)]
prComp<-prcomp(smallspam)
prComp
smallspam<-spam[, c(32, 34)]
prComp<-prcomp(smallspam)
prComp
plot(prComp$x[1], prComp$x[2])
plot(prComp$x[,1], prComp$x[,2])
prComp<-prcomp(x = log10(spam[-58]+1))
prComp
preProc<-preProcess(x = log10(spam[,-58]+1), method = "pca", pcaComp = 2)
spamPC<-predict(object = preproc, newdata = log10(spam[,-58]+1))
plot(spamPC[,1], spamPC[,2], col=typeColour)
preProc<-preProcess(x = log10(spam[,-58]+1), method = "pca", pcaComp = 2)
spamPC<-predict(object = preproc, newdata = log10(spam[,-58]+1))
plot(spamPC[,1], spamPC[,2], col=typeColour)
spamPC<-predict(preproc, newdata = log10(spam[,-58]+1))
spamPC<-predict(object = preProc, newdata = log10(spam[,-58]+1))
plot(spamPC[,1], spamPC[,2], col=typeColour)
typeColour<-((spam$type=="spam")*1 + 1)
plot(spamPC[,1], spamPC[,2], col=typeColour)
spamPC
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
which(names(training %in% IL))
which(names(training %in% "IL"))
grep(pattern = "IL", x = names(training))
inds<-grep(pattern = "IL", x = names(training))
names(training)[inds]
require(reshape2)
training[, inds]
dim(inds)
length(inds)
dim(training[, inds])
spamPC
prComp
preProc<-preProcess(x = training[, inds], method="pca", thresh = 0.8)
preProc
head(training$diagnosis)
inds<-grep(pattern = "IL", x = names(training))
digInd<-grep(pattern = "diagnosis", x = names(training))
inds
digInd
c(digInd, inds)
inds<-grep(pattern = "IL", x = names(training))
digInd<-grep(pattern = "diagnosis", x = names(training))
allInds<-c(digInd, inds)
preProc1<-preProcess(x = training[, allInds], method = "pca")
preProc2<-preProcess(x = training[, allInds], method = "pca", thresh = .8)
head(training[,allInds])
inds<-grep(pattern = "IL", x = names(training))
names(training)[inds]
?grep
inds<-grep(pattern = "^IL", x = names(training))
names(training)[inds]
inds<-grep(pattern = "^IL", x = names(training))
names(training)[inds]
preProc<-preProcess(x = training[, inds], method="pca", thresh = 0.8)
preProc
inds<-grep(pattern = "^IL", x = names(training))
digInd<-grep(pattern = "diagnosis", x = names(training))
allInds<-c(digInd, inds)
preProc1<-preProcess(x = training[, allInds], method = "pca")
preProc2<-preProcess(x = training[, allInds], method = "pca", thresh = .8)
head(training[, allInds])
head(spam[, 58])
preProc1<-preProcess(x = training2[, -1], method = "pca")
preProc2<-preProcess(x = training2[, -1], method = "pca", thresh = .8)
training2<-training[,allInds]
preProc1<-preProcess(x = training2[, -1], method = "pca")
preProc2<-preProcess(x = training2[, -1], method = "pca", thresh = .8)
preProc1
preProc1<-preProcess(x = training2[, -1], method = "pca")
trainPC1<-predict(preProc1, newdata = training2[, -1])
modelFit<-train(x = training2$diagnosis~.,method = "glm", data = trainPC1 )
trainPC1
modelFit<-train(x = training$diagnosis~.,method = "glm", data = trainPC1 )
modelFit<-train(x = training$diagnosis ~.,method = "glm", data = trainPC1 )
modelFit<-train(training2$diagnosis ~.,method = "glm", data = trainPC1 )
modelFit
inds<-grep(pattern = "^IL", x = names(training))
digInd<-grep(pattern = "diagnosis", x = names(training))
allInds<-c(digInd, inds)
training2<-training[,allInds]; testing2<-testing[,allInds]
preProc1<-preProcess(x = training2[, -1], method = "pca")
trainPC1<-predict(preProc1, newdata = training2[, -1])
modelFit1<-train(training2$diagnosis ~.,method = "glm", data = trainPC1 )
testPC1<-predict(preProc1, newdata = testing2[, -1])
confusionMatrix(testing2$diagnosis, predict(modelFit1, testPC1))
modelFit<-train(type ~., data = training, method = "glm")
modelFit<-train(diagnosis ~., data = training2, method = "glm")
modelFit
inds<-grep(pattern = "^IL", x = names(training))
digInd<-grep(pattern = "diagnosis", x = names(training))
allInds<-c(digInd, inds)
training2<-training[,allInds]; testing2<-testing[,allInds]
modelFit<-train(diagnosis ~., data = training2, method = "glm")
predictions<-predict(object = modelFit, newdata = testing2)
confusionMatrix(data = predictions, testing2$diagnosis)
preProc<-preProcess(x = training2[, -1], method = "pca", thresh = 0.8)
trainPC<-predict(prePro1, newdata = training2[, -1])
pc_modelFit<-train(training2$diagnosis ~.,method = "glm", data = trainPC)
testPC1<-predict(preProc1, newdata = testing2[, -1])
confusionMatrix(testing2$diagnosis, predict(pc_modelFit, testPC))
preProc<-preProcess(x = training2[, -1], method = "pca", thresh = 0.8)
trainPC<-predict(preProc, newdata = training2[, -1])
pc_modelFit<-train(training2$diagnosis ~.,method = "glm", data = trainPC)
testPC<-predict(preProc, newdata = testing2[, -1])
confusionMatrix(testing2$diagnosis, predict(pc_modelFit, testPC))
trainPC
summary(trainPC)
setwd("~/Desktop/PMLNotes")
library(knitr)
knit("PMLcaret")
knit("PMLcaret.Rmd")
?lm
---
title: "RMQuiz2"
author: "Varun Boodram"
date: "October 18, 2014"
output: html_document
---
Consider the following data with x as the predictor and y as as the outcome.
```{r}
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
```
Give a P-value for the two sided hypothesis test of whether $\beta1$ from a linear regression model is 0 or not.
```{r}
regr<-lm(formula = y~x)
regr
plot(x,y)
par(mfrow=c(1,1))
plot(x,y)
---
title: "RMQuiz2"
author: "Varun Boodram"
date: "October 18, 2014"
output: html_document
---
Consider the following data with x as the predictor and y as as the outcome.
```{r}
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
```
Give a P-value for the two sided hypothesis test of whether $\beta1$ from a linear regression model is 0 or not.
```{r}
regr<-lm(formula = x~y)
regr
plot(x,y)
data(diamond)
library(UsingR)
data(diamond)
coef(lm(price~carat, diamond))
new_diamond_carats<-c(.16, .27, .34)
---
title: "RMQuiz2"
author: "Varun Boodram"
date: "October 18, 2014"
output: html_document
---
### Statistical Linear regression models
Least squares is an estimation tool, how do we do inference?
There are a bunch of points in cartesian cordinates, and all we wanted was a line that minimized the vertical distances to the data. This is not a statistical model
Consider developing a probabilistic model for linear regression
$$Y_i=\beta_0+\beta_1X_i+\epsilon$$
where the$\epsilon$ are assumed iid $N\sim(0,1)$.Because of this, the conditional expectations of the Ys given the Xs, which we denote $\mu_i$ is
$$E[Y_i\vert X_i=x_i]=\mu_i=\beta_0+\beta_1x_i$$ This is easy to see: take the expected values
$$
\begin{aligned}
E[Y_i\vert X_i=x_i]&=E[\beta_0+\beta_1X_i+\epsilon]\\
&=\beta_0+\beta_1X_i+E[\epsilon]\\
&=\beta_0+\beta_1X_i+0
\end{aligned}
$$
because $E[\epsilon]=0$. Likelihood equivalent model specification is that the are independent $N\sim(0,1)$.
ML estimates of and are the least squares estimates
$$\hat{\beta_1}=R_{X,Y}\frac{S_Y}{S_X}$$
$$\hat{\beta_0}=\hat{Y}-\hat{\beta_1}\hat{X}$$
Interpreting the coefficients
* $\beta_0$ is the expected value of the response when the predictor is 0
$$E[Y\vert X=0]=\beta_0+0\beta_1$=\beta_0$$
Note, this isn't always of interest, for example when is impossible or far outside of the range of data. (X is blood pressure, or height etc.)
*Consider that
$$
\begin{aligned}
Y_i&=\beta_0+\beta_1X_i+\epsilon\\
&=\beta_0+a\beta_1\beta_1(X_i-a)+\epsilon\\
&=\hat{\beta_0}+\beta_1(X_i-a)+\epsilon
\end{aligned}$$
So, shifting your $X$ values by value $a$ changes the intercept, but not the slope.
Often $a$ is set to so that the intercept is interpretted as the expected response at the average $X$ value.
eg
```{r, message=FALSE}
library(UsingR)
data(diamond)
plot(diamond$carat, diamond$price)
abline(lm(price~carat, data = diamond), lwd=2)
coef(lm(price~carat, diamond))
```
* We estimate an expected 3721.0249  dollar increase in price for every carat increase in mass of diamond
* The intercept -259.6259 is the expected price of a 0 carat diamond.
The intercept makes no sense. we can obtain a more interpretable intercept with
```{r}
fit<-lm(price~I(carat-mean(carat)), data = diamond); coef(fit)
```
Thus $500.1 is the expected price for the average sized diamond of the data (0.2042 carats).
_Predicting the price of a diamond_
```{r}
new_diamond_carats<-c(.16, .27, .34)
predict(object = fit, newdata = data.frame(carat = new_diamond_carats))
```
Consider the following data with x as the predictor and y as as the outcome.
```{r}
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
```
Give a P-value for the two sided hypothesis test of whether $\beta1$ from a linear regression model is 0 or not.
```{r}
# lm(outcome, predictor)
regr<-lm(formula = y~x)
regr
```
do.call(cbind(x, y))
cbind(x, y)
data<-data.frame(cbind(x, y))
regr<-lm(formula = y~x, data)
regr
summary(regr)
.75^2
sqrt(92,16)
sqrt(92.16)
sqrt(.9216)
qt(.975, df = 25)
data(mtcars)
regr<-lm(mpg~weight, data = mtcars)
names(mtcars)
regr<-lm(mpg~wt, data = mtcars)
summary(regr)
nrow(mtcars)
data(mtcars)
regr<-lm(mpg~wt, data = mtcars)
summary(regr)
b1<--5.3445
SE_b1<-0.5591
ci<-b1+(-1,1)*qt(0.975, 30)*SE_b1
data(mtcars)
regr<-lm(mpg~wt, data = mtcars)
summary(regr)
b1<--5.3445
SE_b1<-0.5591
ci<-b1+c(-1,1)*qt(0.975, 30)*SE_b1
ci
?mtcars
mtcars$wt
predict(object = regr, newdata = data.frame(wt = 3000))
predict(object = regr, newdata = data.frame(wt = 3))
predicted+c(-1,1)*qt(0.975, 30)*SE_b1
predicted<-predict(object = regr, newdata = data.frame(wt = 3))
predicted+c(-1,1)*qt(0.975, 30)*SE_b1
predicted+c(-1,1)*qt(0.975, 30)*1.8776
predicted+c(-1,1)*qt(0.975, 30)*SE_b1
data(mtcars)
regr<-lm(mpg~wt*2, data = mtcars)
summary(regr)
b1<--5.3445
SE_b1<-0.5591
ci<-b1+c(-1,1)*qt(0.975, 30)*SE_b1
ci
aov(formula = mpg~wt, data = mtcars)
model1<-lm(mpg~1, mtcars)
model1
summary(model1)
model1<-lm(mpg~1, mtcars)
anova(model1, regr)
847.7252/278.3219
